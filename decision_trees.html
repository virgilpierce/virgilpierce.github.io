<!DOCTYPE html>
<!--**************************************-->
<!--*    Generated from PreTeXt source   *-->
<!--*    on 2019-11-19T13:28:12-07:00    *-->
<!--*                                    *-->
<!--*      https://pretextbook.org       *-->
<!--*                                    *-->
<!--**************************************-->
<html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Decsion Trees</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width,  initial-scale=1.0, user-scalable=0, minimum-scale=1.0, maximum-scale=1.0">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['\\(','\\)']]
    },
    asciimath2jax: {
        ignoreClass: ".*",
        processClass: "has_am"
    },
    jax: ["input/AsciiMath"],
    extensions: ["asciimath2jax.js"],
    TeX: {
        extensions: ["extpfeil.js", "autobold.js", "https://pretextbook.org/js/lib/mathjaxknowl.js", ],
        // scrolling to fragment identifiers is controlled by other Javascript
        positionToHash: false,
        equationNumbers: { autoNumber: "none", useLabelIds: true, },
        TagSide: "right",
        TagIndent: ".8em",
    },
    // HTML-CSS output Jax to be dropped for MathJax 3.0
    "HTML-CSS": {
        scale: 88,
        mtextFontInherit: true,
    },
    CommonHTML: {
        scale: 88,
        mtextFontInherit: true,
    },
});
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML-full"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.12/pretext.js"></script><script src="https://pretextbook.org/js/0.12/pretext_add_on.js"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.2/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.2/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.2/toc.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.2/colors_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.2/setcolors.css" rel="stylesheet" type="text/css">
<!-- 2019-10-12: Temporary - CSS file for experiments with styling --><link href="developer.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.2/features.css" rel="stylesheet" type="text/css">
<script>var logged_in = false;
var role = 'student';
var guest_access = true;
var login_required = false;
var js_version = 0.12;
</script>
</head>
<body class="mathbook-book has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div class="hidden-content" style="display:none">\(\newcommand{\doubler}[1]{2#1}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\)</div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="datascience.html"><span class="title">Data Science with Python</span></a></h1>
<p class="byline">Virgil U Pierce</p>
</div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3"><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="section-54.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="datascience.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="section-55.html" title="Next">Next</a></span></div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="section-54.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="datascience.html" title="Up">Up</a><a class="next-button button toolbar-item" href="section-55.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link"><a href="frontmatter-1.html" data-scroll="frontmatter-1"><span class="title">Front Matter</span></a></li>
<li class="link">
<a href="course_syllabus.html" data-scroll="course_syllabus"><span class="codenumber">1</span> <span class="title">Course Syllabus</span></a><ul>
<li><a href="section-1.html" data-scroll="section-1">Class and Instructor Details</a></li>
<li><a href="section-2.html" data-scroll="section-2">Course Description</a></li>
<li><a href="section-3.html" data-scroll="section-3">Textbook and Software</a></li>
<li><a href="section-4.html" data-scroll="section-4">Learning Objectives / Outcomes for the Course</a></li>
<li><a href="section-5.html" data-scroll="section-5">Communicating</a></li>
<li><a href="section-6.html" data-scroll="section-6">Course Outline</a></li>
<li><a href="section-7.html" data-scroll="section-7">Connections with Industrial Mathematics</a></li>
<li><a href="section-8.html" data-scroll="section-8">Assessments</a></li>
<li><a href="section-9.html" data-scroll="section-9">UNCO Policy Statements</a></li>
</ul>
</li>
<li class="link">
<a href="data_science_introduction.html" data-scroll="data_science_introduction"><span class="codenumber">2</span> <span class="title">Introduction to Data Science</span></a><ul>
<li><a href="section-10.html" data-scroll="section-10">Anaconda, Jupyter, and Python</a></li>
<li><a href="section-11.html" data-scroll="section-11">Github</a></li>
<li><a href="section-12.html" data-scroll="section-12">Python</a></li>
<li><a href="section-13.html" data-scroll="section-13">Some Prelimaries</a></li>
<li><a href="section-14.html" data-scroll="section-14">First Motivating Example - Baseball Players</a></li>
<li><a href="section-15.html" data-scroll="section-15">Second Motivating Example - Abalone Characteristics</a></li>
<li><a href="section-16.html" data-scroll="section-16">Third Motivating Example - US Income Levels</a></li>
<li><a href="section-17.html" data-scroll="section-17">Fourth Motivating Example - Mushroom Characteristics</a></li>
<li><a href="section-18.html" data-scroll="section-18">Fifth Motivating Example - House Prices</a></li>
<li><a href="section-19.html" data-scroll="section-19">Sixth Motivating Example - Running Data from Garmin</a></li>
<li><a href="section-20.html" data-scroll="section-20">Seventh Motivating Example - Berlin Airbnb Data</a></li>
<li><a href="section-21.html" data-scroll="section-21">Eighth Motivating Example - Colorado Child Care</a></li>
<li><a href="section-22.html" data-scroll="section-22">Ninth Motivating Example - Flight Delays at DEN</a></li>
<li><a href="section-23.html" data-scroll="section-23">Tenth Motivating Example - Image Classification</a></li>
<li><a href="section-24.html" data-scroll="section-24">Left for a future class - Unsupervised Learning</a></li>
</ul>
</li>
<li class="link">
<a href="data.html" data-scroll="data"><span class="codenumber">3</span> <span class="title">Data</span></a><ul>
<li><a href="section-25.html" data-scroll="section-25">What is Data</a></li>
<li><a href="section-26.html" data-scroll="section-26">Supervised versus Unsupervised Learning</a></li>
<li><a href="section-27.html" data-scroll="section-27">Where to get Data</a></li>
</ul>
</li>
<li class="link">
<a href="tools.html" data-scroll="tools"><span class="codenumber">4</span> <span class="title">Tools of the Trade</span></a><ul>
<li><a href="section-28.html" data-scroll="section-28">Python and Jupyter</a></li>
<li><a href="section-29.html" data-scroll="section-29">Development</a></li>
<li><a href="section-30.html" data-scroll="section-30">Versioning Control</a></li>
</ul>
</li>
<li class="link">
<a href="process.html" data-scroll="process"><span class="codenumber">5</span> <span class="title">The Data Science Process</span></a><ul>
<li><a href="section-31.html" data-scroll="section-31">Professional Ethics</a></li>
<li><a href="section-32.html" data-scroll="section-32">Controlling for Error</a></li>
<li><a href="section-33.html" data-scroll="section-33">Error in Categorization Problems</a></li>
</ul>
</li>
<li class="link">
<a href="wrangling.html" data-scroll="wrangling"><span class="codenumber">6</span> <span class="title">Wrangling the Data</span></a><ul>
<li><a href="section-34.html" data-scroll="section-34">Formatting the Data</a></li>
<li><a href="section-35.html" data-scroll="section-35">Dealing with Strings</a></li>
<li><a href="section-36.html" data-scroll="section-36">Dealing with Categorical Data</a></li>
<li><a href="section-37.html" data-scroll="section-37">Dealing with Missing Data</a></li>
<li><a href="section-38.html" data-scroll="section-38">Dealing with Images</a></li>
</ul>
</li>
<li class="link">
<a href="resampling.html" data-scroll="resampling"><span class="codenumber">7</span> <span class="title">Resampling</span></a><ul>
<li><a href="section-39.html" data-scroll="section-39">Cross Validation</a></li>
<li><a href="section-40.html" data-scroll="section-40">Bootstraps</a></li>
</ul>
</li>
<li class="link">
<a href="EDA.html" data-scroll="EDA"><span class="codenumber">8</span> <span class="title">Exploratory Data Analysis</span></a><ul><li><a href="section-41.html" data-scroll="section-41">Nonlinear Relations</a></li></ul>
</li>
<li class="link">
<a href="linear_regression.html" data-scroll="linear_regression"><span class="codenumber">9</span> <span class="title">Linear Regression</span></a><ul>
<li><a href="section-42.html" data-scroll="section-42">Calculus Approach to Linear Regression</a></li>
<li><a href="section-43.html" data-scroll="section-43">Linear Regression as Projection</a></li>
</ul>
</li>
<li class="link">
<a href="pca.html" data-scroll="pca"><span class="codenumber">10</span> <span class="title">Principal Component Analysis</span></a><ul>
<li><a href="section-44.html" data-scroll="section-44">Eigenvalue Decomposition of Square Matrix</a></li>
<li><a href="section-45.html" data-scroll="section-45">Singular Value Decomposition</a></li>
</ul>
</li>
<li class="link">
<a href="k-nn.html" data-scroll="k-nn"><span class="codenumber">11</span> <span class="title">k-Nearest Neighbors</span></a><ul>
<li><a href="section-46.html" data-scroll="section-46">Checking Performance with Bootstraps</a></li>
<li><a href="section-47.html" data-scroll="section-47">Normalization</a></li>
<li><a href="section-48.html" data-scroll="section-48">k-Nearest Neighbors with Many Factors</a></li>
<li><a href="section-49.html" data-scroll="section-49">k-Nearest Neighbors for Regression</a></li>
</ul>
</li>
<li class="link">
<a href="ridge_and_lasso.html" data-scroll="ridge_and_lasso"><span class="codenumber">12</span> <span class="title">Ridge and Lasso Regression</span></a><ul>
<li><a href="section-50.html" data-scroll="section-50">House Pricing Data: Linear Regression</a></li>
<li><a href="section-51.html" data-scroll="section-51">Ridge Regression</a></li>
<li><a href="section-52.html" data-scroll="section-52">Lasso Regression</a></li>
</ul>
</li>
<li class="link">
<a href="lda_svm.html" data-scroll="lda_svm"><span class="codenumber">13</span> <span class="title">Linear Discrimant Analysis and Support Vector Machines</span></a><ul>
<li><a href="section-53.html" data-scroll="section-53">Linear Discriminant Analysis</a></li>
<li><a href="section-54.html" data-scroll="section-54">Support Vector Machines</a></li>
</ul>
</li>
<li class="link active">
<a href="decision_trees.html" data-scroll="decision_trees"><span class="codenumber">14</span> <span class="title">Decsion Trees</span></a><ul>
<li><a href="section-55.html" data-scroll="section-55">Regression Trees</a></li>
<li><a href="section-56.html" data-scroll="section-56">Classification Tree</a></li>
<li><a href="section-57.html" data-scroll="section-57">High Dimensional Data and Decision Trees</a></li>
<li><a href="section-58.html" data-scroll="section-58">Discussion of Decision Tree Algorithms</a></li>
</ul>
</li>
<li class="link">
<a href="neural-networks.html" data-scroll="neural-networks"><span class="codenumber">15</span> <span class="title">Neural Networks</span></a><ul>
<li><a href="section-59.html" data-scroll="section-59">Neural Network for Regression</a></li>
<li><a href="section-60.html" data-scroll="section-60">Neural Networks for Classification</a></li>
<li><a href="section-61.html" data-scroll="section-61">Neural Network with a Large Number of Features</a></li>
</ul>
</li>
<li class="link">
<a href="ensemble.html" data-scroll="ensemble"><span class="codenumber">16</span> <span class="title">General Ensemble Models</span></a><ul>
<li><a href="section-62.html" data-scroll="section-62">Why do Ensemble Models Work</a></li>
<li><a href="section-63.html" data-scroll="section-63">Ensemble Models for Regression</a></li>
</ul>
</li>
<li class="link">
<a href="unsupervised.html" data-scroll="unsupervised"><span class="codenumber">17</span> <span class="title">Unsupervised Learning</span></a><ul><li><a href="section-64.html" data-scroll="section-64">Clustering</a></li></ul>
</li>
</ul></nav><div class="extras"><nav><a class="mathbook-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content"><section class="chapter" id="decision_trees"><h2 class="heading">
<span class="type">Chapter</span> <span class="codenumber">14</span> <span class="title">Decsion Trees</span>
</h2>
<a href="decision_trees.html" class="permalink">Â¶</a><section class="introduction" id="introduction-31"><p id="p-823">Today we will learn a new type of model, called <em class="emphasis">Decision Trees</em> and then explore a number of models using these algorithms. Decision trees represent a significant departure from previous models. Their primary advantage is that they produce models that are easy to explain to <em class="emphasis">non-experts</em> and they are also capable of distilling the most important features in a model.</p>
<p id="p-824">However Decision Trees do not typically perform well on data as a model (again we see this sort of dichotomy between types of models), so we will also explore some techniques for using multiple decision trees as a model. These will have improved performance as models but will not be as easy to interpret.</p>
<p id="p-825">Decsision Trees are especially important models in my work on Student Success as they represent the actual placement process we use at universities to determine what mathematics course students should take and what supports they need. <a class="external" href="https://www.unco.edu/nhs/mathematical-sciences/placement/results.aspx" target="_blank">Here is an example of our placement chart at UNC.</a>  You will see very quickly that this is a basic example of a decision tree. With that in mind you can see that they appear in many other places, though perhaps as models that have not been developed algorithmicly, trained on data, or tested.</p>
<p id="p-826">Perhaps the best place to start is with an example:</p>
<figure class="figure-like" id="listing-363"><pre class="console"><b>import pandas as pa
import matplotlib.pyplot as plt
import matplotlib.colors as pltcolor
import numpy as np
</b></pre>
<figcaption><span class="type">Listing</span> <span class="codenumber">14.0.1.</span> </figcaption></figure><figure class="figure-like" id="listing-364"><pre class="console"><b>mpg = pa.read_csv('Data Sets/auto-mpg.csv', names=['mpg', 'cylinders', 'displacement', 'horsepower', 
                                                   'weight', 'acceleration', 'model year', 'origin', 'car name'])
mpg.head(10)
</b>    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \
0  18.0          8         307.0        130    3504          12.0          70   
1  15.0          8         350.0        165    3693          11.5          70   
2  18.0          8         318.0        150    3436          11.0          70   
3  16.0          8         304.0        150    3433          12.0          70   
4  17.0          8         302.0        140    3449          10.5          70   
5  15.0          8         429.0        198    4341          10.0          70   
6  14.0          8         454.0        220    4354           9.0          70   
7  14.0          8         440.0        215    4312           8.5          70   
8  14.0          8         455.0        225    4425          10.0          70   
9  15.0          8         390.0        190    3850           8.5          70   

   origin                       car name  
0       1  \t"chevrolet chevelle malibu"  
1       1          \t"buick skylark 320"  
2       1         \t"plymouth satellite"  
3       1              \t"amc rebel sst"  
4       1                \t"ford torino"  
5       1           \t"ford galaxie 500"  
6       1           \t"chevrolet impala"  
7       1          \t"plymouth fury iii"  
8       1           \t"pontiac catalina"  
9       1         \t"amc ambassador dpl"
</pre>
<figcaption><span class="type">Listing</span> <span class="codenumber">14.0.2.</span> </figcaption></figure><figure class="figure-like" id="listing-365"><pre class="console"><b>mpg = mpg[mpg.horsepower!='?']
mpg.horsepower = mpg.horsepower.astype('int')
</b></pre>
<figcaption><span class="type">Listing</span> <span class="codenumber">14.0.3.</span> </figcaption></figure><figure class="figure-like" id="listing-366"><pre class="console"><b>X = np.array(mpg[['horsepower', 'weight']])
y = np.array(mpg['mpg'])
</b></pre>
<figcaption><span class="type">Listing</span> <span class="codenumber">14.0.4.</span> </figcaption></figure><figure class="figure-like" id="listing-367"><pre class="console"><b>import numpy.random as rn
</b></pre>
<figcaption><span class="type">Listing</span> <span class="codenumber">14.0.5.</span> </figcaption></figure><p id="p-827">One note here:  I've realized that we probably should be using a different permutation for each run even across multiple models so for this class I have moved the training/testing set division inside of the plot command. This also means that the fit for the model is in there as well. The function now returns the fitted model.</p>
<figure class="figure-like" id="listing-368"><pre class="console"><b># A bit of code for plotting the contour in a regression problem with two predictors
# Also prints out the training and testing errors

def plot_reg_model(reg, X, y):

    # We shuffle the data using a random permutation

    n = X.shape[0]
    test = int(0.20*n)            # We will use a test set made up of 20% of the data from our sample
    perm = rn.permutation(n)   
    X = X[perm]
    y = y[perm]
    X_test = X[:test]       # Then create the test
    y_test = y[:test]
    X_train = X[test:]     # and train sets
    y_train = y[test:]
    
    reg.fit(X_train, y_train) # Fit the model
     
    nn = 200
    # Plot the decision boundary. For that, we will assign a color to each
    # point in the mesh [x_min, m_max]x[y_min, y_max].
    x_min, x_max = X[:, 0].min()-0.1, X[:, 0].max()+0.1
    y_min, y_max = X[:, 1].min()-0.1, X[:, 1].max()+0.1
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, nn),   # Changed the function to use linspace rather than arrange
        np.linspace(y_min, y_max, nn))                    # This keeps us from having to adjust h.
    Z = reg.predict(np.c_[xx.ravel(), yy.ravel()]) # predict

    # Put the result into a color plot
    Z = Z.reshape(xx.shape)

    plt.figure(figsize=(8, 6))
    plt.contour(xx, yy, Z)
    
    plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, marker='o')
    plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, marker='+');
    
    print('Training R2: {}'.format(reg.score(X_train, y_train)))
    print('Testing R2: {}'.format(reg.score(X_test, y_test)))
    
    return reg
</b></pre>
<figcaption><span class="type">Listing</span> <span class="codenumber">14.0.6.</span> </figcaption></figure><p id="p-828">Check how the existing regression algorithms from our toolbox do on this data:</p>
<figure class="figure-like" id="listing-369"><pre class="console"><b>from sklearn.linear_model import LinearRegression
</b></pre>
<figcaption><span class="type">Listing</span> <span class="codenumber">14.0.7.</span> </figcaption></figure><figure class="figure-like" id="listing-370"><pre class="console"><b>reg = LinearRegression()
plot_reg_model(reg, X, y)
plt.savefig('14.1.png')
</b>Training R2: 0.7129395751477017
Testing R2: 0.6747799693458862
</pre>
<div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="Images/14.1.png" style="width: 100%; height: auto;" alt=""></div>
<figcaption><span class="type">Listing</span> <span class="codenumber">14.0.8.</span> </figcaption></figure><figure class="figure-like" id="listing-371"><pre class="console"><b>from sklearn.linear_model import Ridge
</b></pre>
<figcaption><span class="type">Listing</span> <span class="codenumber">14.0.9.</span> </figcaption></figure><figure class="figure-like" id="listing-372"><pre class="console"><b>reg = Ridge(alpha=2)
plot_reg_model(reg, X, y);
plt.savefig('14.2.png')
</b>Training R2: 0.6991902274911
Testing R2: 0.7214973525403486
</pre>
<div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="Images/14.2.png" style="width: 100%; height: auto;" alt=""></div>
<figcaption><span class="type">Listing</span> <span class="codenumber">14.0.10.</span> </figcaption></figure><figure class="figure-like" id="listing-373"><pre class="console"><b>from sklearn.linear_model import Lasso
</b></pre>
<figcaption><span class="type">Listing</span> <span class="codenumber">14.0.11.</span> </figcaption></figure><figure class="figure-like" id="listing-374"><pre class="console"><b>reg=Lasso(alpha=1)
plot_reg_model(reg, X, y);
plt.savefig('14.3.png')
</b>Training R2: 0.7167854279907314
Testing R2: 0.6300921805228554
</pre>
<div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="Images/14.3.png" style="width: 100%; height: auto;" alt=""></div>
<figcaption><span class="type">Listing</span> <span class="codenumber">14.0.12.</span> </figcaption></figure><p id="p-829">Interestingly we get slightly better performance from Lasso depsite only using two features.</p>
<figure class="figure-like" id="listing-375"><pre class="console"><b>from sklearn.neighbors import KNeighborsRegressor
</b></pre>
<figcaption><span class="type">Listing</span> <span class="codenumber">14.0.13.</span> </figcaption></figure><figure class="figure-like" id="listing-376"><pre class="console"><b>knn = KNeighborsRegressor(n_neighbors=6)
plot_reg_model(knn, X, y);
plt.savefig('14.4.png')
</b>Training R2: 0.7923221210245921
Testing R2: 0.7347342158771607
</pre>
<div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="Images/14.4.png" style="width: 100%; height: auto;" alt=""></div>
<figcaption><span class="type">Listing</span> <span class="codenumber">14.0.14.</span> </figcaption></figure></section><nav class="summary-links"><ul>
<li><a href="section-55.html"><span class="codenumber">14.1</span> <span class="title">Regression Trees</span></a></li>
<li><a href="section-56.html"><span class="codenumber">14.2</span> <span class="title">Classification Tree</span></a></li>
<li><a href="section-57.html"><span class="codenumber">14.3</span> <span class="title">High Dimensional Data and Decision Trees</span></a></li>
<li><a href="section-58.html"><span class="codenumber">14.4</span> <span class="title">Discussion of Decision Tree Algorithms</span></a></li>
</ul></nav></section></div></main>
</div>
<div class="login-link"><span id="loginlogout" class="login">login</span></div>
<script src="https://pretextbook.org/js/0.12/login.js"></script>
</body>
</html>
