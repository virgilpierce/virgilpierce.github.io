<!DOCTYPE html>
<html lang="en-US">
<!--**************************************-->
<!--*    Generated from PreTeXt source   *-->
<!--*    on 2019-09-18T11:30:27-06:00    *-->
<!--*                                    *-->
<!--*      https://pretextbook.org       *-->
<!--*                                    *-->
<!--**************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body>
<h6 class="heading"><span class="type">Paragraph</span></h6>
<p>The first method is for cross validation. It is essentially the same as the Training / Testing division of the dataset that we've used, except that the division is repeated, the model retrained, and the error recomputed for multiple divisions into training and testing sets. Here is an example where we repeat the process five times, using 20% of the data each time as a testing set. Note that the only randomness is the initial ordering of the dataset, and so this means that each sample is included in one of the testing sets and in four of the training sets. This will give us a sense of how our model depends on the training sets, and how the testing set error varies.</p>
<span class="incontext"><a href="section-39.html#p-569">in-context</a></span>
</body>
</html>
