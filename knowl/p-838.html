<!DOCTYPE html>
<html lang="en-US">
<!--**************************************-->
<!--*    Generated from PreTeXt source   *-->
<!--*    on 2019-11-11T16:53:57-07:00    *-->
<!--*                                    *-->
<!--*      https://pretextbook.org       *-->
<!--*                                    *-->
<!--**************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body>
<h6 class="heading"><span class="type">Paragraph</span></h6>
<p>Those of you taking the <em class="emphasis">Graph Theory Course</em> or the <em class="emphasis">Algorithms Course</em> have seen trees before. Note that the decision trees here are a subset of the trees you could build by dividing the samples by splitting until you reach leaves with less than 10 nodes. The subset is much smaller because the splitting has to preserve samples that are close in the feature coordinates being used, however for even a moderatley big dataset it will still be to large to effectively search all possible decision trees for the one that performs the best.</p>
<span class="incontext"><a href="section-58.html#p-838">in-context</a></span>
</body>
</html>
