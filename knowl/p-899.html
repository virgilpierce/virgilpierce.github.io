<!DOCTYPE html>
<html lang="en-US">
<!--**************************************-->
<!--*    Generated from PreTeXt source   *-->
<!--*    on 2019-11-19T13:25:42-07:00    *-->
<!--*                                    *-->
<!--*      https://pretextbook.org       *-->
<!--*                                    *-->
<!--**************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body>
<h6 class="heading"><span class="type">Paragraph</span></h6>
<p>The last few models we have studied have demonstrated that combining multiple models (like a <em class="emphasis">Random Forests</em> or <em class="emphasis">Boosting</em>) or otherwise building massive averaging into a model (like we did with <em class="emphasis">Neural Networks</em>) is a method capable of producing flexible models that are somewhat protected from overfitting. Models that are built by combining multiple models have the drawback of being harder to interpret.</p>
<span class="incontext"><a href="ensemble.html#p-899">in-context</a></span>
</body>
</html>
